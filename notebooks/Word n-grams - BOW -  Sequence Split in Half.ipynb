{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word n-grams (Bag of Words - BOW)\n",
    "------\n",
    "**What it does**: Runs two bag of words models -- one on words from the first half of the tweet, one from the second half. From the paper linked below.\n",
    "\n",
    "_we also hypothesize that the words located towards the end of a tweet are more important than other words, because people usually summarize or highlight their points in the end. For example, “I hate it when stuff like that happens,.. ;/ thank god it worked out. #thankful.”. Although “hate” appears in the first half of the tweet, the overall emotion is dominated by “thank” in the latter half. We encoded the position information into a feature by attaching a number (i.e, 1 or 2) to each n-gram to indicate whether it is in the first half or the second half of the tweet_\n",
    "\n",
    "source: http://knoesis.wright.edu/library/download/wenbo_socialcom_2012.pdf\n",
    "\n",
    "Technically it loads the entire twitter vocabulary from a `CountVectorizer` first, so you change any settings in the model run on the entire tweet corpus. Then it applies that vocabulary to the two separate corpuses generated by the first and second half of the string.\n",
    "\n",
    "**Strengths**: May capture additional positional information.\n",
    "\n",
    "**Weaknesses**: Worse performance on STS-Gold compared to a traditional BOW.\n",
    "\n",
    "**Hyperparameters**:\n",
    "- `CountVectorizer`:\n",
    "  - `ngram_range`: the window length of words to look at -- `(min, max)`. In this notebook, we look at unigrams and bigrams\n",
    "  - `min_df`, `max_df`: The minimum and maximum document freqency for an n-gram, respectively. Can be a count (`3`) or a percent (`0.95`)\n",
    "  - `stop_words`: Whether to remove stopwords based on the `english` word list. Can input another stopword list.\n",
    "  - `binary`: Whether to convert to a binary (yes/no) occurence. Can also just apply later in pipeline using `Binarizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sts_gold = pd.read_csv('../data/sts_gold_v03/sts_gold_tweet.csv', index_col='id', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467933112</th>\n",
       "      <td>0</td>\n",
       "      <td>the angel is going to miss the athlete this we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323395086</th>\n",
       "      <td>0</td>\n",
       "      <td>It looks as though Shaq is getting traded to C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467968979</th>\n",
       "      <td>0</td>\n",
       "      <td>@clarianne APRIL 9TH ISN'T COMING SOON ENOUGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990283756</th>\n",
       "      <td>0</td>\n",
       "      <td>drinking a McDonalds coffee and not understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988884918</th>\n",
       "      <td>0</td>\n",
       "      <td>So dissapointed Taylor Swift doesnt have a Twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            polarity                                              tweet\n",
       "id                                                                     \n",
       "1467933112         0  the angel is going to miss the athlete this we...\n",
       "2323395086         0  It looks as though Shaq is getting traded to C...\n",
       "1467968979         0     @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH \n",
       "1990283756         0  drinking a McDonalds coffee and not understand...\n",
       "1988884918         0  So dissapointed Taylor Swift doesnt have a Twi..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = sts_gold['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_str = 'this is a sentence I am about to split in half'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_tweet(string, half='first'):\n",
    "    split_str = string.split()\n",
    "    halfway = int(len(split_str) / 2)\n",
    "    if half == 'first':\n",
    "        return ' '.join(split_str[:halfway])\n",
    "    if half == 'second':\n",
    "        return ' '.join(split_str[halfway:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_firsthalf = tweets.apply(lambda x: split_tweet(x))\n",
    "tweets_secondhalf = tweets.apply(lambda x: split_tweet(x, half='second'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), min_df=3, max_df=.95, stop_words='english')\n",
    "cv.fit_transform(tweets)\n",
    "all_vocabulary = cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_first = CountVectorizer(vocabulary=all_vocabulary)\n",
    "bow_first = cv_first.fit_transform(tweets_firsthalf)\n",
    "colnames_1 = [i + \"_1\" for i in cv_first.get_feature_names()]\n",
    "bow_first_df = pd.DataFrame(bow_first.toarray(), index=tweets_firsthalf.index, columns=colnames_1)\n",
    "\n",
    "cv_second = CountVectorizer(vocabulary=all_vocabulary)\n",
    "bow_second = cv_second.fit_transform(tweets_secondhalf)\n",
    "colnames_2 = [i + \"_2\" for i in cv_second.get_feature_names()]\n",
    "\n",
    "bow_second_df = pd.DataFrame(bow_second.toarray(), index=tweets_secondhalf.index, columns=colnames_2)\n",
    "\n",
    "bow_combined = pd.concat([bow_first_df, bow_second_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10_1</th>\n",
       "      <th>100_1</th>\n",
       "      <th>101_1</th>\n",
       "      <th>12_1</th>\n",
       "      <th>13_1</th>\n",
       "      <th>14_1</th>\n",
       "      <th>15_1</th>\n",
       "      <th>1st_1</th>\n",
       "      <th>20_1</th>\n",
       "      <th>24_1</th>\n",
       "      <th>...</th>\n",
       "      <th>yay_2</th>\n",
       "      <th>yea_2</th>\n",
       "      <th>yeah_2</th>\n",
       "      <th>year_2</th>\n",
       "      <th>years_2</th>\n",
       "      <th>yep_2</th>\n",
       "      <th>yes_2</th>\n",
       "      <th>yesterday_2</th>\n",
       "      <th>youtube_2</th>\n",
       "      <th>youtube channel_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467933112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323395086</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467968979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990283756</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988884918</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            10_1  100_1  101_1  12_1  13_1  14_1  15_1  1st_1  20_1  24_1  \\\n",
       "id                                                                          \n",
       "1467933112     0      0      0     0     0     0     0      0     0     0   \n",
       "2323395086     0      0      0     0     0     0     0      0     0     0   \n",
       "1467968979     0      0      0     0     0     0     0      0     0     0   \n",
       "1990283756     0      0      0     0     0     0     0      0     0     0   \n",
       "1988884918     0      0      0     0     0     0     0      0     0     0   \n",
       "\n",
       "                  ...          yay_2  yea_2  yeah_2  year_2  years_2  yep_2  \\\n",
       "id                ...                                                         \n",
       "1467933112        ...              0      0       0       0        0      0   \n",
       "2323395086        ...              0      0       0       0        0      0   \n",
       "1467968979        ...              0      0       0       0        0      0   \n",
       "1990283756        ...              0      0       0       0        0      0   \n",
       "1988884918        ...              0      0       0       0        0      0   \n",
       "\n",
       "            yes_2  yesterday_2  youtube_2  youtube channel_2  \n",
       "id                                                            \n",
       "1467933112      0            0          0                  0  \n",
       "2323395086      0            0          0                  0  \n",
       "1467968979      0            0          0                  0  \n",
       "1990283756      0            0          0                  0  \n",
       "1988884918      0            0          0                  0  \n",
       "\n",
       "[5 rows x 2356 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [('DUMMY', DummyClassifier(strategy='most_frequent')),\n",
    "          ('mNB' , MultinomialNB()),\n",
    "          ('bNB' , BernoulliNB()),\n",
    "          ('svc' , SVC(probability=True)),\n",
    "          ('rf' , RandomForestClassifier()),\n",
    "          ('lr' , LogisticRegressionCV())\n",
    "         ]\n",
    "models.append(('eclf', VotingClassifier(estimators=[models[i] for i in [1, 3, 4, 5]], voting='soft')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL\tMEAN CV\tMIN CV\tMAX CV\n",
      "DUMMY\t0.6893\t0.6887\t0.6897\n",
      "mNB\t0.8137\t0.8079\t0.8162\n",
      "bNB\t0.7886\t0.7696\t0.803\n",
      "svc\t0.7183\t0.7069\t0.7291\n",
      "rf\t0.7567\t0.7328\t0.7956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pbaumgartner/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/pbaumgartner/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/pbaumgartner/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\t0.7916\t0.777\t0.8054\n",
      "eclf\t0.8107\t0.7931\t0.8276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pbaumgartner/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "print('{0}\\t{1:<1}\\t{2:<4}\\t{3:<4}'.format(\"MODEL\", \"MEAN CV\", \"MIN CV\", \"MAX CV\"))\n",
    "\n",
    "for name, model in models:    \n",
    "    X, Y = bow_combined, (sts_gold['polarity'] == 4).ravel()\n",
    "    \n",
    "    if name == 'bNB':\n",
    "        binarize = Binarizer()\n",
    "        X = binarize.fit_transform(X)\n",
    "    elif name == 'svc':\n",
    "        ss = StandardScaler()\n",
    "        X = X.values\n",
    "        X = ss.fit_transform(X)\n",
    "        \n",
    "    cv = cross_val_score(model, X, Y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print('{0}\\t{1:<3}\\t{2:<4}\\t{3:<4}'.format(name, round(cv.mean(), 4), round(cv.min(), 4), round(cv.max(), 4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
