{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entities Count (Bag of Named Entities)\n",
    "------\n",
    "**What it does**: Finds all named entities in a corpus, then flags the occurence of each entity within each tweet.\n",
    "\n",
    "**Strengths**: \n",
    "\n",
    "**Weaknesses**: Takes a long time to compute.\n",
    "\n",
    "**Hyperparameters**:  None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sts_gold = pd.read_csv('../data/sts_gold_v03/sts_gold_tweet.csv', index_col='id', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467933112</th>\n",
       "      <td>0</td>\n",
       "      <td>the angel is going to miss the athlete this we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323395086</th>\n",
       "      <td>0</td>\n",
       "      <td>It looks as though Shaq is getting traded to C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467968979</th>\n",
       "      <td>0</td>\n",
       "      <td>@clarianne APRIL 9TH ISN'T COMING SOON ENOUGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990283756</th>\n",
       "      <td>0</td>\n",
       "      <td>drinking a McDonalds coffee and not understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988884918</th>\n",
       "      <td>0</td>\n",
       "      <td>So dissapointed Taylor Swift doesnt have a Twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            polarity                                              tweet\n",
       "id                                                                     \n",
       "1467933112         0  the angel is going to miss the athlete this we...\n",
       "2323395086         0  It looks as though Shaq is getting traded to C...\n",
       "1467968979         0     @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH \n",
       "1990283756         0  drinking a McDonalds coffee and not understand...\n",
       "1988884918         0  So dissapointed Taylor Swift doesnt have a Twi..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We're going to combine all text together and form a Named Entity Dictionary for Count Vectorizer\n",
    "alltext = ' '.join([i for i in sts_gold['tweet']])\n",
    "\n",
    "#remove hashtags\n",
    "alltext_nohash = re.sub(r'\\#\\w+','', alltext)\n",
    "\n",
    "#remove mentions\n",
    "alltext_nohash_nomentions = re.sub(r'\\@\\w+','', alltext_nohash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(alltext_nohash_nomentions)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "chunked_nes = nltk.ne_chunk(pos_tags, binary=True)\n",
    "nes = [' '.join(map(lambda x: x[0], ne.leaves())) for ne in chunked_nes if isinstance(ne, nltk.tree.Tree)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n"
     ]
    }
   ],
   "source": [
    "ne_vocabulary = list(set(nes))\n",
    "print(len(ne_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 687) 0.00157153714367 3\n"
     ]
    }
   ],
   "source": [
    "ne_df = pd.DataFrame()\n",
    "for word in ne_vocabulary:\n",
    "    ne_df[word] = sts_gold['tweet'].str.count(word)\n",
    "    \n",
    "print(ne_df.shape, ne_df.values.mean(), ne_df.values.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [('DUMMY', DummyClassifier(strategy='most_frequent')),\n",
    "          ('mNB' , MultinomialNB()),\n",
    "          ('bNB' , BernoulliNB()),\n",
    "          ('svc' , SVC(probability=True)),\n",
    "          ('rf' , RandomForestClassifier()),\n",
    "          ('lr' , LogisticRegressionCV())\n",
    "         ]\n",
    "models.append(('eclf', VotingClassifier(estimators=[models[i] for i in [1, 3, 4, 5]], voting='soft')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL\tMEAN CV\tMIN CV\tMAX CV\n",
      "DUMMY\t0.6893\t0.6887\t0.6897\n",
      "mNB\t0.7173\t0.7044\t0.7315\n",
      "bNB\t0.7109\t0.6961\t0.7266\n",
      "svc\t0.7045\t0.6985\t0.7143\n",
      "rf\t0.7124\t0.6897\t0.7365\n",
      "lr\t0.708\t0.6995\t0.7167\n",
      "eclf\t0.7168\t0.7083\t0.7241\n"
     ]
    }
   ],
   "source": [
    "print('{0}\\t{1:<1}\\t{2:<4}\\t{3:<4}'.format(\"MODEL\", \"MEAN CV\", \"MIN CV\", \"MAX CV\"))\n",
    "\n",
    "for name, model in models:    \n",
    "    X, Y = ne_df, (sts_gold['polarity'] == 4).ravel()\n",
    "    \n",
    "    if name == 'bNB':\n",
    "        binarize = Binarizer()\n",
    "        X = binarize.fit_transform(X)\n",
    "    elif name == 'svc':\n",
    "        ss = StandardScaler()\n",
    "        #X = X.toarray()\n",
    "        X = ss.fit_transform(X)\n",
    "        \n",
    "    cv = cross_val_score(model, X, Y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print('{0}\\t{1:<3}\\t{2:<4}\\t{3:<4}'.format(name, round(cv.mean(), 4), round(cv.min(), 4), round(cv.max(), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
