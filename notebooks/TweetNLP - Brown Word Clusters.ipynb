{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TweetNLP - Brown Word Clusters\n",
    "------\n",
    "**What it does**:\n",
    "Maps word occurences to a cluster assignment, based on a clustering model built on 56m tweets.  \n",
    "Source: http://www.cs.cmu.edu/~ark/TweetNLP/#resources\n",
    "\n",
    "**Strengths**: Reduces sparsity of feature space compared to BOW\n",
    "\n",
    "**Weaknesses**:\n",
    "\n",
    "**Hyperparameters**: Since clusters are hierarchical, they can have different cutoffs to get a different number of clusters. The fully extended clustering has 1000 clusters based on a 16 digit binary string, and can be reduced to a 4 digit binary string. This is implemented in the `generate_cluster_string` argument of `cutoff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sts_gold = pd.read_csv('../data/sts_gold_v03/sts_gold_tweet.csv', index_col='id', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467933112</th>\n",
       "      <td>0</td>\n",
       "      <td>the angel is going to miss the athlete this we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323395086</th>\n",
       "      <td>0</td>\n",
       "      <td>It looks as though Shaq is getting traded to C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467968979</th>\n",
       "      <td>0</td>\n",
       "      <td>@clarianne APRIL 9TH ISN'T COMING SOON ENOUGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990283756</th>\n",
       "      <td>0</td>\n",
       "      <td>drinking a McDonalds coffee and not understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988884918</th>\n",
       "      <td>0</td>\n",
       "      <td>So dissapointed Taylor Swift doesnt have a Twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            polarity                                              tweet\n",
       "id                                                                     \n",
       "1467933112         0  the angel is going to miss the athlete this we...\n",
       "2323395086         0  It looks as though Shaq is getting traded to C...\n",
       "1467968979         0     @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH \n",
       "1990283756         0  drinking a McDonalds coffee and not understand...\n",
       "1988884918         0  So dissapointed Taylor Swift doesnt have a Twi..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = sts_gold['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusterDict = {}\n",
    "with open('../lexicons/tweetnlp_clusters/50mpaths2.txt', 'r') as f:\n",
    "    reader=csv.reader(f,delimiter='\\t')\n",
    "    for cluster, word, freq in reader:\n",
    "        clusterDict[word] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_cluster_string(string, tokenizer, cutoff=16):\n",
    "    if cutoff < 4 or cutoff > 16:\n",
    "        print(\"cutoff must be between 4 and 16\")\n",
    "        return None\n",
    "    clusterList = []\n",
    "    for token in tokenizer.tokenize(string):\n",
    "        try:\n",
    "            token = token.lower()\n",
    "            cluster = clusterDict[token][:cutoff]\n",
    "            clusterList.append(cluster)\n",
    "        except KeyError:\n",
    "            clusterList.append('NOCLUSTER')\n",
    "    return ' '.join(clusterList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustered = [generate_cluster_string(tweet, tt) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "clus = cv.fit_transform(clustered)\n",
    "\n",
    "# use below for data frame\n",
    "clus_df = pd.DataFrame(clus.toarray(), index=tweets.index, columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000</th>\n",
       "      <th>000100</th>\n",
       "      <th>000101</th>\n",
       "      <th>000110</th>\n",
       "      <th>0001110</th>\n",
       "      <th>0001111</th>\n",
       "      <th>001000</th>\n",
       "      <th>001001</th>\n",
       "      <th>0010100</th>\n",
       "      <th>001010100</th>\n",
       "      <th>...</th>\n",
       "      <th>1111111101110</th>\n",
       "      <th>11111111011110</th>\n",
       "      <th>11111111011111</th>\n",
       "      <th>1111111110</th>\n",
       "      <th>111111111100</th>\n",
       "      <th>111111111101</th>\n",
       "      <th>111111111110</th>\n",
       "      <th>1111111111110</th>\n",
       "      <th>1111111111111</th>\n",
       "      <th>nocluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467933112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323395086</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467968979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990283756</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988884918</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 960 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0000  000100  000101  000110  0001110  0001111  001000  001001  \\\n",
       "id                                                                           \n",
       "1467933112     0       0       0       0        0        0       0       0   \n",
       "2323395086     0       0       0       0        0        0       0       0   \n",
       "1467968979     0       0       0       0        0        0       0       0   \n",
       "1990283756     0       0       0       0        0        0       1       0   \n",
       "1988884918     0       0       0       0        0        0       0       0   \n",
       "\n",
       "            0010100  001010100    ...      1111111101110  11111111011110  \\\n",
       "id                                ...                                      \n",
       "1467933112        0          0    ...                  0               0   \n",
       "2323395086        0          0    ...                  0               0   \n",
       "1467968979        0          0    ...                  0               0   \n",
       "1990283756        0          0    ...                  0               0   \n",
       "1988884918        0          0    ...                  0               0   \n",
       "\n",
       "            11111111011111  1111111110  111111111100  111111111101  \\\n",
       "id                                                                   \n",
       "1467933112               0           0             0             0   \n",
       "2323395086               0           1             0             0   \n",
       "1467968979               0           0             0             0   \n",
       "1990283756               0           1             0             0   \n",
       "1988884918               0           0             0             0   \n",
       "\n",
       "            111111111110  1111111111110  1111111111111  nocluster  \n",
       "id                                                                 \n",
       "1467933112             0              0              0          0  \n",
       "2323395086             0              0              0          1  \n",
       "1467968979             0              0              0          1  \n",
       "1990283756             0              0              0          0  \n",
       "1988884918             0              0              0          0  \n",
       "\n",
       "[5 rows x 960 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [('DUMMY', DummyClassifier(strategy='most_frequent')),\n",
    "          ('mNB' , MultinomialNB()),\n",
    "          ('bNB' , BernoulliNB()),\n",
    "          ('svc' , SVC(probability=True)),\n",
    "          ('rf' , RandomForestClassifier()),\n",
    "          ('lr' , LogisticRegressionCV())\n",
    "         ]\n",
    "models.append(('eclf', VotingClassifier(estimators=[models[i] for i in [1, 3, 4, 5]], voting='soft')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL\tMEAN CV\tMIN CV\tMAX CV\n",
      "DUMMY\t0.6893\t0.6887\t0.6897\n",
      "mNB\t0.8618\t0.8547\t0.8719\n",
      "bNB\t0.8638\t0.8554\t0.8725\n",
      "svc\t0.7925\t0.7647\t0.8088\n",
      "rf\t0.7979\t0.7882\t0.8079\n",
      "lr\t0.852\t0.826\t0.8916\n",
      "eclf\t0.8589\t0.8358\t0.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pbaumgartner/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/pbaumgartner/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "print('{0}\\t{1:<1}\\t{2:<4}\\t{3:<4}'.format(\"MODEL\", \"MEAN CV\", \"MIN CV\", \"MAX CV\"))\n",
    "\n",
    "for name, model in models:    \n",
    "    X, Y = clus, (sts_gold['polarity'] == 4).ravel()\n",
    "    \n",
    "    if name == 'bNB':\n",
    "        binarize = Binarizer()\n",
    "        X = binarize.fit_transform(X)\n",
    "    elif name == 'svc':\n",
    "        ss = StandardScaler()\n",
    "        X = X.toarray()\n",
    "        X = ss.fit_transform(X)\n",
    "        \n",
    "    cv = cross_val_score(model, X, Y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print('{0}\\t{1:<3}\\t{2:<4}\\t{3:<4}'.format(name, round(cv.mean(), 4), round(cv.min(), 4), round(cv.max(), 4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
